{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938b4860",
   "metadata": {},
   "source": [
    "### Text classification: predict which of two artists is more likely to use a given word/sentence\n",
    "##### 09th of Mai 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df536581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from thefuzz import fuzz, process\n",
    "import pandas as pd\n",
    "import string\n",
    "from string import digits\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import operator\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72515863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data: Download html text from website of a given artist\n",
    "html = requests.get(\"https://www.lyrics.com/artist/Gorillaz/476055\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a pattern to extract the links to each song\n",
    "pattern= r'href=\"(\\/lyric.+?)\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full urls to each song lyrics and sort out dublicates\n",
    "link = re.findall(pattern, string=html)\n",
    "url_prefix = \"https://www.lyrics.com\"\n",
    "full_url = []\t\t\t\t\t# Will contain full working urls to each lyric\n",
    "pure_title = []\t\t\t\t\t# Will contain only the song title of each song\n",
    "dubli_check = []\t\t\t\t# Will be used to sort out dublicates\n",
    "for title in link:\n",
    "\ta = re.findall(r\"\\/lyric-?l?f?\\/\\d+\\/Gorillaz\\/\", title)\n",
    "\tb = title.replace(str(a[0]), \"\")\n",
    "\tif b in dubli_check:\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tfull_url.append(url_prefix+title)\n",
    "\t\tpure_title.append(b)\n",
    "\t\tdubli_check.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing all urls to the respective title \n",
    "df = pd.DataFrame()\n",
    "df[\"url\"] = full_url\n",
    "df[\"title\"] = pure_title\n",
    "df = df.sort_values(by=[\"title\"])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again reduce the number of dublicates by comparing the song titles\n",
    "pure_title.sort()\n",
    "pure_title_red = []\n",
    "c = None\n",
    "for count, title in enumerate(pure_title):\n",
    "\tif c == None:\n",
    "\t\tc = title\n",
    "\t\tpure_title_red.append(title)\n",
    "\telse:\n",
    "\t\tif fuzz.token_set_ratio(c, title) == 100:\n",
    "\t\t\tdf = df.drop([count])\n",
    "\t\telse:\n",
    "\t\t\tc = title\n",
    "\t\t\tpure_title_red.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to have a continues index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save HTML files of every song (run only one time!)\n",
    "# for count, title in enumerate(df[\"title\"]):\n",
    "# \thtml_songs = requests.get(df[\"url\"][count]).text\n",
    "# \twith open (f\"Gorillaz/{title}.txt\", \"w\") as f:\n",
    "# \t \tf.write(html_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e727f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create corpus filled with lyrics\n",
    "gorillaz = []\t\t\t\t\t# Will contain only lyrics from Gorillaz\n",
    "corpus=[]\t\t\t\t\t\t# Will contain all lyrics from both artists\n",
    "for title in df[\"title\"]:\n",
    "\twith open(f\"Gorillaz/{title}.txt\", \"r\") as f:\n",
    "\t\tx = f.read()\n",
    "\ttitle_soup = BeautifulSoup(x, \"html.parser\")\n",
    "\ttry:\n",
    "\t\tlyrics = title_soup.find(class_=\"lyric-body\").text\n",
    "\t\tgorillaz.append(lyrics)\n",
    "\t\tcorpus.append(lyrics)\n",
    "\texcept:\n",
    "\t\tprint(\"No lyrics found for:\", title)\n",
    "\t\tgorillaz.append(\"Nolyrics\")\n",
    "\t\tcorpus.append(\"Nolyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create DataFrame with title, url and lyrics and tokenize \n",
    "dic_gor = {\"title\": pure_title_red, \"url\": df[\"url\"], \"lyrics\":gorillaz}\n",
    "df_gor = pd.DataFrame.from_dict(dic_gor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f76231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Performing all previous steps for the second artist (EoDM)\n",
    "# Get Data: Download html text from website of a given artist\n",
    "html = requests.get(\"https://www.lyrics.com/artist/Eagles-of-Death-Metal/643679\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a pattern to extract the links to each song\n",
    "pattern= r'href=\"(\\/lyric.+?)\">'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full urls to each song lyrics and sort out dublicates\n",
    "link = re.findall(pattern, string=html)\n",
    "url_prefix = \"https://www.lyrics.com\"\n",
    "full_url = []\t\t\t\t\t# Will contain full working urls to each lyric\n",
    "pure_title = []\t\t\t\t\t# Will contain only the song title of each song\n",
    "dubli_check = []\t\t\t\t# Will be used to sort out dublicates\n",
    "for title in link:\n",
    "\ta = re.findall(r\"\\/lyric-?l?f?\\/\\d+\\/Eagles\\+of\\+Death\\+Metal\\/\", title)\n",
    "\tb = title.replace(str(a[0]), \"\")\n",
    "\tif b in dubli_check:\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tfull_url.append(url_prefix+title)\n",
    "\t\tpure_title.append(b)\n",
    "\t\tdubli_check.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d91735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing all urls to the respective title \n",
    "df = pd.DataFrame()\n",
    "df[\"url\"] = full_url\n",
    "df[\"title\"] = pure_title\n",
    "df = df.sort_values(by=[\"title\"])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again reduce the number of dublicates by comparing the song titles\n",
    "pure_title.sort()\n",
    "pure_title_red = []\n",
    "c = None\n",
    "for count, title in enumerate(pure_title):\n",
    "\tif c == None:\n",
    "\t\tc = title\n",
    "\t\tpure_title_red.append(title)\n",
    "\telse:\n",
    "\t\tif fuzz.token_set_ratio(c, title) == 100:\n",
    "\t\t\tdf = df.drop([count])\n",
    "\t\telse:\n",
    "\t\t\tc = title\n",
    "\t\t\tpure_title_red.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f96259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to have a continues index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3721155",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save HTML files of every song (run only one time!)\n",
    "# for count, title in enumerate(df[\"title\"]):\n",
    "# \thtml_songs = requests.get(df[\"url\"][count]).text\n",
    "# \twith open (f\"Eagles_of_Death_Metal/{title}.txt\", \"w\") as f:\n",
    "# \t \tf.write(html_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19244354",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create corpus filled with lyrics\n",
    "eodm = []\t\t\t\t\t\t# Will contain only lyrics from EoDM\n",
    "for title in df[\"title\"]:\n",
    "\twith open(f\"Eagles_of_Death_Metal/{title}.txt\", \"r\") as f:\n",
    "\t\tx = f.read()\n",
    "\ttitle_soup = BeautifulSoup(x, \"html.parser\")\n",
    "\ttry:\n",
    "\t\tlyrics = title_soup.find(class_=\"lyric-body\").text\n",
    "\t\teodm.append(lyrics)\n",
    "\t\tcorpus.append(lyrics)\n",
    "\texcept:\n",
    "\t\tprint(\"No lyrics found for:\", title)\n",
    "\t\teodm.append(\"Nolyrics\")\n",
    "\t\tcorpus.append(\"Nolyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create DataFrame with title, url and lyrics and tokenize\n",
    "dic_eodm = {\"title\": pure_title_red, \"url\": df[\"url\"], \"lyrics\":eodm}\n",
    "df_eodm = pd.DataFrame.from_dict(dic_eodm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2dc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels will be used for creating the vectorized DataFrame\n",
    "labels = [\"Gorillaz\"]*173+[\"Eagles_of_Death_Metal\"]*80\t\t\t# As many labels as songs needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ML model on the lyrics corpus\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "vectorizer.fit(corpus)\n",
    "vecto_trans = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2132ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with count of words in each song of the artists\n",
    "final_df = pd.DataFrame(vecto_trans.toarray(), columns=vectorizer.get_feature_names_out(), index=labels)\n",
    "final_df.reset_index(inplace=True)\n",
    "final_df.rename(columns={\"index\": \"band\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e08e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into features (X) and target variable (y)\n",
    "X = final_df.iloc[:, 1:]\n",
    "y = final_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncode target variable (0 = Gorillaz, 1 = EoDM)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "ohc = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "ohc.fit(y)\n",
    "ohc_t = ohc.transform(y)\n",
    "y = pd.DataFrame(ohc_t, columns=ohc.get_feature_names_out())\n",
    "y = y.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23342ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a RandomForestClassifier as a ML model\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "forest.fit(X_train.astype(str), y_train)\n",
    "pred = forest.predict(X_test.astype(str))\n",
    "print(\"Accuracy score for Random Forest:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision score for Random Forest:\",precision_score(y_test, pred))\n",
    "print(\"Recall score for Random Forest:\",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LogisticRegression as a ML model\n",
    "reg = LogisticRegression(random_state=1)\n",
    "reg.fit(X_train.astype(str), y_train)\n",
    "pred = reg.predict(X_test.astype(str))\n",
    "print(\"Accuracy score for LogReg:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision score for LogReg:\",precision_score(y_test, pred))\n",
    "print(\"Recall score for LogReg:\",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes as a ML model\n",
    "naive = MultinomialNB()\n",
    "naive.fit(X_train.astype(str), y_train)\n",
    "naive.score(X_train.astype(str), y_train)\n",
    "pred = naive.predict(X_test.astype(str))\n",
    "print(\"Accuracy score for Naive Bayes:\", accuracy_score(y_test, pred))\n",
    "print(\"Precision score for Naive Bayes:\",precision_score(y_test, pred))\n",
    "print(\"Recall score for Naive Bayes:\",recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc737f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return most predicitve words based on LogisticRegression\n",
    "print(\"Most predictive words for EoDM are:\", operator.itemgetter(*np.argsort(reg.coef_[0]))(vectorizer.get_feature_names_out())[-20:])\n",
    "print(\"Most predictive words for Gorillaz are:\", operator.itemgetter(*np.argsort(reg.coef_[0]))(vectorizer.get_feature_names_out())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e33bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets the user enter a word or sentence and predicts from which artist it probably is\n",
    "song_input=[]\n",
    "song_input.append(input())\n",
    "vecto_trans = vectorizer.transform(song_input)\n",
    "vector_input_df = pd.DataFrame(vecto_trans.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "pred_input = naive.predict(vector_input_df.astype(str))\n",
    "if pred_input == 0:\n",
    "    print(f\"The lyrics {song_input} are probably from the Gorillaz!\")\n",
    "    print(\"Probability:\", naive.predict_proba(vector_input_df.astype(str))[:,0])\n",
    "\n",
    "else:\n",
    "    print(f\"The lyrics {song_input} are probably from the Eagles of Death Metal!\")\n",
    "    print(\"Probability:\", naive.predict_proba(vector_input_df.astype(str))[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
